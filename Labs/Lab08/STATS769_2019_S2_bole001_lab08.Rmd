---
title: "STATS 769 - Lab 08 - bole001"
author: "Bernard O'Leary"
date: "06 October 2019"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Dataset description

Dataset is the same as what we used for Lab06 and Lab07, this time we use the entire dataset though rather than just 100000 records. The data set for this lab is a single large CSV file containing electric vehicle trips.

# Read in the data

We read in the data using three diffrent approaches:

- read.csv() without specifying colClasses will bring the data through in auto-detected/assigned format, which is convenient but not particularly efficient. 
- read.csv() specifying colClasses will bring the data through in a specific format, this is more work upfront as we need to inspect the data and decide on the best fit for the data format, but far more efficient as we can be very specific about what comes through into the dataframe.
- data.table::fread() specifying colClasses not only enables us to gain the efficiency of specifying data format, but also using the datatable structure which is inherently a more efficient structure than the dataframe.

For each techniques we will inspect the execution time using the system.time() function. Execution time for read.csv() is significantly shorter when specifying colClasses. We see further improvement in performance when using data.table::fread() with colClasses specified. All results have dimensions 6532457 x 16.

```{r}
# Specify location of the raw data
#path <- "C:\\Files\\"
path <- "/course/data.austintexas.gov/"
filename <- paste0(path, "Dockless_Vehicle_Trips.csv")

# Read in using read.csv with no colClasses specified
system.time(tripsReadCsvWithoutColClasses <- read.csv(filename, stringsAsFactors=FALSE)[-1,])
# Check dimensions - should be 6532457 x 16
dim(tripsReadCsvWithoutColClasses)

# Read in using read.csv with colClasses specified
system.time(
    tripsReadCsvWithColClasses <- read.csv(filename, stringsAsFactors=FALSE,
                      colClasses=c("character",
                                   "character",
                                   "factor",
                                   "integer",
                                   "integer",
                                   "character",
                                   "character",
                                   "character",
                                   "integer",
                                   "integer",
                                   "integer",
                                   "integer",
                                   "integer",
                                   "integer",
                                   "character",
                                   "character"))[-1,]
)
# Check dimensions - should be 6532457 x 16
dim(tripsReadCsvWithColClasses)

# Read in using data.table::fread with colClasses specified
system.time(
    tripDT <- data.table::fread(filename, stringsAsFactors=FALSE,
                      colClasses=c("character",
                                   "character",
                                   "factor",
                                   "integer",
                                   "integer",
                                   "character",
                                   "character",
                                   "character",
                                   "integer",
                                   "integer",
                                   "integer",
                                   "integer",
                                   "integer",
                                   "integer",
                                   "character",
                                   "character"))[-1,]
)
# Check dimensions - should be 6532457 x 16
dim(tripDT)
```

# Create logged columns

Measure time it takes to remove non-zero number and then create logged values for Trip.Distance and Trip.Duration and add them to the data.table tripsDT. Add the time up and print it out.

```{r}
# Get the log variables
time1 <- system.time(tripDTsub <- subset(tripDT, tripDT$`Trip Distance` > 0 & tripDT$`Trip Duration` > 0))
time2 <- system.time(tripDTsub$logDuration <- log(tripDTsub$`Trip Duration`))
time3 <- system.time(tripDTsub$logDistance <- log(tripDTsub$`Trip Distance`))
# Print the total time taken 
time1 + time2 + time3
```

# Faster creation of log variables

Use properties of the data.table data structure to enable much faster creation of logged varibles for Trip.Duration and Trip.Distance. I am not sure how to omit non-zero values in place, have tried to use na.omit and also na.rm=TRUE but was unable to get either to work, so using existing subsetting approach.

```{r}
# Get the log variables
time1 <- system.time(tripDT <- subset(tripDT, tripDT$`Trip Distance` > 0 & tripDT$`Trip Duration` > 0))
time2 <- system.time(tripDT[, logDuration := log(tripDT$`Trip Duration`)])
time3 <- system.time(tripDT[, logDistance := log(tripDT$`Trip Distance`)])
# Print the total time taken
time1 + time2 + time3
```

# Define labels and MSE function 

As provided in the Lab08 instruction sheet. Measure the time taken to run the procesdure and the memory used by using the profile toolkit. The measured results suggest that by far the most amount of time used by this code is in fitting the linear model, specifically the lm() function.

```{r}
# Define function and variables
labels <- rep(1:10, length.out=nrow(tripDT))
groups <- sample(labels)
# Define MSE function
mse <- function(i, formula) {
  ## cat(i, "\n")
  testSet <- groups == i
  trainSet <- groups != i
  fit <- lm(formula,
    data.frame(x=tripDT[trainSet, logDistance], y=tripDT[trainSet, logDuration]))
  pred <- predict(fit, data.frame(x=tripDT$logDistance[testSet]))
  mean((pred - tripDT$logDuration[testSet])^2, na.rm=TRUE)
}
# Run the code, visualise and measure performance
library(profvis)
# Call gc() to make the effect of garbage collection more stable
gc() 
profvis({
  time1 <- system.time(mean(sapply(1:10, mse, y ~ x)))
})
# Print the elapsed time
time1
```

# Optimise the MSE function to perform faster

Compare optimised time using MSE2 function (defined below) to original MSE function (defined above). 

```{r}
# Define optimised MSE2 function
mse2 <- function(i, formula) {
  ## cat(i, "\n")
  testSet <- groups == i
  trainSet <- groups != i
  # Added "na.action = na.omit" parameter to the lm() function
  fit <- lm(formula,
    data.frame(x=tripDT[trainSet, logDistance], y=tripDT[trainSet, logDuration]), na.action = na.omit)
  pred <- predict(fit, data.frame(x=tripDT$logDistance[testSet]))
  mean((pred - tripDT$logDuration[testSet])^2, na.rm=TRUE)
}
# Run the code, visualise and measure performance
# Call gc() to make the effect of garbage collection more stable
gc() 
profvis({
  time1 <- system.time(mean(sapply(1:10, mse2, y ~ x)))
})
# Print the elapsed time
time1
```

# Measure memory usage to run the RMD file

The command used to measure the elapsed time in seconds of the RMD file was as follows:

```
/usr/bin/time -f "%e" Rscript -e 'library("rmarkdown"); render("STATS769_2019_S2_bole001_lab08.Rmd")'
```

The document takes approximately 190 seconds (over three minutes) to process - I'm not sure how I would be able to reduce this much further though as even with my optimised MSE2 function removed from processing it takes well over two minutes to run the whole RMD file.

# Summary and Conclusion

We have tried using both the dataframe and datatable structure to process and cleanse data and tried to optimise the MSE function by applying the "na.action = na.omit" to the lm() function that consumes most of the processing time for the function - this did not appear to make much difference though. We used the Linux time function to measure the running time of the RMD in an effort to have it run in under 2 minutes. 

